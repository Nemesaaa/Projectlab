{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sumolib\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch_geometric.data as Data\n",
    "import torch_geometric.utils as pyg_utils\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's read in the graph file and see if it works properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to read in the network we work with into a networkx object with the nodes and edges, no features yet\n",
    "def read_sumo_net(filename):\n",
    "    net = sumolib.net.readNet(filename)\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add nodes\n",
    "    for node in net.getNodes():\n",
    "        G.add_node(node.getID(), pos=(node.getCoord()))\n",
    "    # Add edges\n",
    "    for edge in net.getEdges():\n",
    "        for lane in edge.getLanes():\n",
    "            edge_id = lane.getEdge().getID()\n",
    "            starting_node_id = net.getEdge(edge_id).getFromNode().getID()\n",
    "            ending_node_id = net.getEdge(edge_id).getToNode().getID()\n",
    "            G.add_edge(starting_node_id, ending_node_id, edge_id = edge_id)\n",
    "    return G\n",
    "\n",
    "#Function to add the features to the network graph we created already\n",
    "\n",
    "def add_edge_features_from_xml(G, xml_filename, interval_begin):\n",
    "    # Parse the XML file\n",
    "    tree = ET.parse(xml_filename)\n",
    "    root = tree.getroot()\n",
    "    #Find the interval corresponding to the interval_begin time \n",
    "    interval = root.find(f'.//interval[@begin=\"{interval_begin}\"]')\n",
    "    #Extract all the features of the edges\n",
    "    edges = interval.findall('.//edge')\n",
    "    for edge in edges:\n",
    "        edge_id = edge.get('id')\n",
    "        edge_features = {}\n",
    "        edge_features['left'] = edge.get('left')\n",
    "        #We can add other features here\n",
    "        #Iterate through the edges in the existing NetworkX graph\n",
    "        for xml_edge_id, xml_edge_data in G.edges.items():\n",
    "            if G.get_edge_data(xml_edge_id[0],xml_edge_id[1])['edge_id'] == edge_id:\n",
    "                G.edges[xml_edge_id].update(edge_features)\n",
    "    return G\n",
    "\n",
    "def nx_to_pyg(graph):\n",
    "    # Convert NetworkX graph to PyTorch Geometric Data object\n",
    "    pyg_data = Data.Data()\n",
    "    #We have to number the nodes, because that is how Data object works\n",
    "    # Mapping between string node IDs and numerical indices\n",
    "    node_id_to_index = {node_id: i for i, node_id in enumerate(graph.nodes)}\n",
    "\n",
    "    # Set node features\n",
    "    num_nodes = graph.number_of_nodes()\n",
    "    node_features = np.zeros((num_nodes, 2))  # Assuming num_features is known, this is important to change, if we want to change something, altough I do not think that will be the case for us\n",
    "    for i, (node, features) in enumerate(graph.nodes(data=True)):\n",
    "        node_features[i] = [features['pos'][0], features['pos'][1]]  # Add node features accordingly, this case the coordinates\n",
    "    pyg_data.x = torch.tensor(node_features, dtype=torch.float)\n",
    "\n",
    "    # Set edge features and edge indices\n",
    "    edge_index = []\n",
    "    edge_features = []\n",
    "    for u, v, features in graph.edges(data=True):\n",
    "        # Map string node IDs to numerical indices\n",
    "        u_index = node_id_to_index[u]\n",
    "        v_index = node_id_to_index[v]\n",
    "        edge_index.append([u_index, v_index])\n",
    "        edge_features.append([float(features['left'])])  # Add edge features accordingly, if we add more features, we have to change this line\n",
    "\n",
    "    pyg_data.edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    pyg_data.edge_attr = torch.tensor(edge_features, dtype=torch.float)\n",
    "\n",
    "    return pyg_data\n",
    "\n",
    "\n",
    "#Function to plot the graph\n",
    "def plot_graph(G):\n",
    "    pos = nx.get_node_attributes(G, 'pos')\n",
    "    nx.draw(G, pos, with_labels=False, node_size=10)\n",
    "    plt.show()\n",
    "Graph = read_sumo_net('s_gyor.net.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[413, 2], edge_index=[2, 504], edge_attr=[504, 1])\n"
     ]
    }
   ],
   "source": [
    "G1 = read_sumo_net('s_gyor.net.xml')\n",
    "G2 = add_edge_features_from_xml(G1,'gyor_forg_15_min.xml',\"0.00\")\n",
    "pyg_data = nx_to_pyg(G2)\n",
    "print(pyg_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 43.],\n",
      "        [  0.],\n",
      "        [ 70.],\n",
      "        [102.],\n",
      "        [ 14.],\n",
      "        [ 14.],\n",
      "        [  1.],\n",
      "        [  3.],\n",
      "        [  3.],\n",
      "        [ 40.],\n",
      "        [ 39.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [ 39.],\n",
      "        [ 39.],\n",
      "        [ 39.],\n",
      "        [ 55.],\n",
      "        [ 55.],\n",
      "        [  2.],\n",
      "        [ 55.],\n",
      "        [  2.],\n",
      "        [  2.],\n",
      "        [  0.],\n",
      "        [  2.],\n",
      "        [  0.],\n",
      "        [140.],\n",
      "        [ 79.],\n",
      "        [142.],\n",
      "        [  2.],\n",
      "        [  0.],\n",
      "        [  6.],\n",
      "        [  6.],\n",
      "        [  2.],\n",
      "        [  0.],\n",
      "        [  2.],\n",
      "        [ 45.],\n",
      "        [ 42.],\n",
      "        [ 50.],\n",
      "        [ 63.],\n",
      "        [ 57.],\n",
      "        [ 63.],\n",
      "        [ 10.],\n",
      "        [  0.],\n",
      "        [136.],\n",
      "        [ 39.],\n",
      "        [ 39.],\n",
      "        [ 39.],\n",
      "        [ 39.],\n",
      "        [ 39.],\n",
      "        [ 39.],\n",
      "        [ 60.],\n",
      "        [ 62.],\n",
      "        [ 51.],\n",
      "        [  1.],\n",
      "        [ 43.],\n",
      "        [  0.],\n",
      "        [ 35.],\n",
      "        [ 26.],\n",
      "        [  2.],\n",
      "        [ 28.],\n",
      "        [ 84.],\n",
      "        [ 28.],\n",
      "        [ 28.],\n",
      "        [ 28.],\n",
      "        [ 47.],\n",
      "        [ 46.],\n",
      "        [ 10.],\n",
      "        [ 20.],\n",
      "        [ 28.],\n",
      "        [  2.],\n",
      "        [  1.],\n",
      "        [  2.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  2.],\n",
      "        [ 33.],\n",
      "        [  4.],\n",
      "        [ 33.],\n",
      "        [ 11.],\n",
      "        [ 42.],\n",
      "        [ 11.],\n",
      "        [ 10.],\n",
      "        [ 28.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  8.],\n",
      "        [  8.],\n",
      "        [  3.],\n",
      "        [  5.],\n",
      "        [  8.],\n",
      "        [  8.],\n",
      "        [  8.],\n",
      "        [  0.],\n",
      "        [ 24.],\n",
      "        [  4.],\n",
      "        [ 42.],\n",
      "        [ 17.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [ 39.],\n",
      "        [  0.],\n",
      "        [ 16.],\n",
      "        [ 16.],\n",
      "        [ 49.],\n",
      "        [ 49.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [ 55.],\n",
      "        [  8.],\n",
      "        [  2.],\n",
      "        [139.],\n",
      "        [ 63.],\n",
      "        [  1.],\n",
      "        [139.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  6.],\n",
      "        [  6.],\n",
      "        [ 16.],\n",
      "        [ 16.],\n",
      "        [ 16.],\n",
      "        [  6.],\n",
      "        [  6.],\n",
      "        [ 16.],\n",
      "        [ 16.],\n",
      "        [ 16.],\n",
      "        [ 16.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [ 16.],\n",
      "        [  3.],\n",
      "        [  0.],\n",
      "        [ 14.],\n",
      "        [  0.],\n",
      "        [  2.],\n",
      "        [  2.],\n",
      "        [  2.],\n",
      "        [  0.],\n",
      "        [  2.],\n",
      "        [  2.],\n",
      "        [ 97.],\n",
      "        [ 45.],\n",
      "        [  6.],\n",
      "        [  6.],\n",
      "        [  6.],\n",
      "        [  2.],\n",
      "        [ 11.],\n",
      "        [ 11.],\n",
      "        [ 42.],\n",
      "        [ 41.],\n",
      "        [ 38.],\n",
      "        [ 24.],\n",
      "        [ 67.],\n",
      "        [ 43.],\n",
      "        [ 80.],\n",
      "        [ 79.],\n",
      "        [142.],\n",
      "        [ 58.],\n",
      "        [ 38.],\n",
      "        [116.],\n",
      "        [  2.],\n",
      "        [  2.],\n",
      "        [ 47.],\n",
      "        [  5.],\n",
      "        [  0.],\n",
      "        [ 13.],\n",
      "        [  7.],\n",
      "        [ 15.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [ 41.],\n",
      "        [  4.],\n",
      "        [  1.],\n",
      "        [  4.],\n",
      "        [ 15.],\n",
      "        [ 11.],\n",
      "        [  1.],\n",
      "        [  2.],\n",
      "        [  2.],\n",
      "        [  2.],\n",
      "        [  2.],\n",
      "        [  2.],\n",
      "        [  2.],\n",
      "        [ 15.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [ 13.],\n",
      "        [ 11.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  5.],\n",
      "        [  6.],\n",
      "        [ 35.],\n",
      "        [ 27.],\n",
      "        [ 14.],\n",
      "        [  0.],\n",
      "        [ 13.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  2.],\n",
      "        [ 49.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [ 11.],\n",
      "        [  0.],\n",
      "        [  6.],\n",
      "        [  1.],\n",
      "        [146.],\n",
      "        [ 78.],\n",
      "        [ 74.],\n",
      "        [  0.],\n",
      "        [  1.],\n",
      "        [ 15.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [ 24.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [ 57.],\n",
      "        [ 65.],\n",
      "        [ 11.],\n",
      "        [ 98.],\n",
      "        [ 43.],\n",
      "        [ 43.],\n",
      "        [ 43.],\n",
      "        [ 43.],\n",
      "        [  0.],\n",
      "        [134.],\n",
      "        [135.],\n",
      "        [127.],\n",
      "        [ 23.],\n",
      "        [155.],\n",
      "        [ 23.],\n",
      "        [ 23.],\n",
      "        [163.],\n",
      "        [  0.],\n",
      "        [ 20.],\n",
      "        [114.],\n",
      "        [ 67.],\n",
      "        [112.],\n",
      "        [ 67.],\n",
      "        [111.],\n",
      "        [112.],\n",
      "        [ 67.],\n",
      "        [110.],\n",
      "        [ 67.],\n",
      "        [ 99.],\n",
      "        [ 99.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [ 76.],\n",
      "        [ 99.],\n",
      "        [ 99.],\n",
      "        [ 78.],\n",
      "        [ 76.],\n",
      "        [ 78.],\n",
      "        [ 80.],\n",
      "        [ 77.],\n",
      "        [ 73.],\n",
      "        [  0.],\n",
      "        [ 50.],\n",
      "        [ 48.],\n",
      "        [ 48.],\n",
      "        [ 48.],\n",
      "        [ 48.],\n",
      "        [ 46.],\n",
      "        [ 48.],\n",
      "        [ 48.],\n",
      "        [ 38.],\n",
      "        [ 38.],\n",
      "        [ 43.],\n",
      "        [ 38.],\n",
      "        [ 43.],\n",
      "        [  0.],\n",
      "        [ 38.],\n",
      "        [ 23.],\n",
      "        [ 23.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [ 39.],\n",
      "        [ 39.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [ 66.],\n",
      "        [  4.],\n",
      "        [ 60.],\n",
      "        [ 42.],\n",
      "        [ 71.],\n",
      "        [ 11.],\n",
      "        [ 11.],\n",
      "        [ 60.],\n",
      "        [ 24.],\n",
      "        [ 13.],\n",
      "        [ 67.],\n",
      "        [ 43.],\n",
      "        [  1.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [ 39.],\n",
      "        [  6.],\n",
      "        [  0.],\n",
      "        [  2.],\n",
      "        [ 43.],\n",
      "        [  0.],\n",
      "        [ 46.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [ 47.],\n",
      "        [ 45.],\n",
      "        [ 41.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  2.],\n",
      "        [  0.],\n",
      "        [  6.],\n",
      "        [  6.],\n",
      "        [  6.],\n",
      "        [134.],\n",
      "        [140.],\n",
      "        [ 63.],\n",
      "        [ 39.],\n",
      "        [  0.],\n",
      "        [ 45.],\n",
      "        [ 38.],\n",
      "        [ 63.],\n",
      "        [ 39.],\n",
      "        [ 27.],\n",
      "        [ 98.],\n",
      "        [ 27.],\n",
      "        [  4.],\n",
      "        [  7.],\n",
      "        [ 11.],\n",
      "        [ 11.],\n",
      "        [ 43.],\n",
      "        [ 43.],\n",
      "        [ 50.],\n",
      "        [ 50.],\n",
      "        [  6.],\n",
      "        [ 11.],\n",
      "        [ 55.],\n",
      "        [ 55.],\n",
      "        [  2.],\n",
      "        [  2.],\n",
      "        [ 24.],\n",
      "        [ 49.],\n",
      "        [ 55.],\n",
      "        [ 60.],\n",
      "        [ 13.],\n",
      "        [ 13.],\n",
      "        [ 43.],\n",
      "        [ 43.],\n",
      "        [ 47.],\n",
      "        [  1.],\n",
      "        [  0.],\n",
      "        [ 42.],\n",
      "        [ 13.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [ 33.],\n",
      "        [ 73.],\n",
      "        [ 33.],\n",
      "        [ 73.],\n",
      "        [  3.],\n",
      "        [ 43.],\n",
      "        [  1.],\n",
      "        [  3.],\n",
      "        [  0.],\n",
      "        [ 22.],\n",
      "        [ 71.],\n",
      "        [101.],\n",
      "        [ 60.],\n",
      "        [  1.],\n",
      "        [ 28.],\n",
      "        [  0.],\n",
      "        [ 49.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [ 51.],\n",
      "        [ 40.],\n",
      "        [ 86.],\n",
      "        [ 80.],\n",
      "        [ 52.],\n",
      "        [ 52.],\n",
      "        [ 40.],\n",
      "        [131.],\n",
      "        [ 43.],\n",
      "        [  0.],\n",
      "        [  7.],\n",
      "        [ 73.],\n",
      "        [  6.],\n",
      "        [  2.],\n",
      "        [  2.],\n",
      "        [ 37.],\n",
      "        [ 50.],\n",
      "        [ 13.],\n",
      "        [ 42.],\n",
      "        [103.],\n",
      "        [  6.],\n",
      "        [  5.],\n",
      "        [ 16.],\n",
      "        [108.],\n",
      "        [ 42.],\n",
      "        [ 16.],\n",
      "        [  0.],\n",
      "        [ 13.],\n",
      "        [  5.],\n",
      "        [ 42.],\n",
      "        [  0.],\n",
      "        [  9.],\n",
      "        [  7.],\n",
      "        [ 21.],\n",
      "        [ 15.],\n",
      "        [ 17.],\n",
      "        [  4.],\n",
      "        [ 21.],\n",
      "        [ 21.],\n",
      "        [  0.],\n",
      "        [ 28.],\n",
      "        [  5.],\n",
      "        [  0.],\n",
      "        [  5.],\n",
      "        [ 52.],\n",
      "        [ 39.],\n",
      "        [  0.],\n",
      "        [ 52.],\n",
      "        [ 40.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  6.],\n",
      "        [ 37.],\n",
      "        [  1.],\n",
      "        [  0.],\n",
      "        [ 50.],\n",
      "        [  0.],\n",
      "        [ 50.],\n",
      "        [ 48.],\n",
      "        [ 48.],\n",
      "        [  0.],\n",
      "        [ 49.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [139.],\n",
      "        [ 21.]])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GNN' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 59\u001b[0m\n\u001b[0;32m     56\u001b[0m edges_to_hide_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(edges_to_hide)\n\u001b[0;32m     57\u001b[0m remaining_edge_index \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39medge_index[:, [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(data\u001b[38;5;241m.\u001b[39medge_index\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m edges_to_hide_set]]  \u001b[38;5;66;03m# Filter out the hidden edges\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining_edge_attr\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Assuming remaining_edge_attr contains the features of the remaining edges\u001b[39;00m\n\u001b[0;32m     61\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     62\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\nemes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nemes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nemes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nemes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:3328\u001b[0m, in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, target):\n\u001b[0;32m   3325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   3326\u001b[0m         mse_loss, (\u001b[38;5;28minput\u001b[39m, target), \u001b[38;5;28minput\u001b[39m, target, size_average\u001b[38;5;241m=\u001b[39msize_average, reduce\u001b[38;5;241m=\u001b[39mreduce, reduction\u001b[38;5;241m=\u001b[39mreduction\n\u001b[0;32m   3327\u001b[0m     )\n\u001b[1;32m-> 3328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m()):\n\u001b[0;32m   3329\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   3330\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis will likely lead to incorrect results due to broadcasting. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3332\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3333\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   3334\u001b[0m     )\n\u001b[0;32m   3335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\nemes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GNN' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "G2 = add_edge_features_from_xml(G1,'gyor_forg_15_min.xml',\"10800.00\")\n",
    "G3 = add_edge_features_from_xml(G1,'gyor_forg_15_min.xml',\"9000.00\")\n",
    "data_training = nx_to_pyg(G2)\n",
    "\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, edge_dim, hidden_dim1, hidden_dim2, hidden_dim3, hidden_dim4, hidden_dim5, hidden_dim6, hidden_dim7, hidden_dim8):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GCNConv(edge_dim, hidden_dim1)\n",
    "        self.conv2 = GCNConv(hidden_dim1, hidden_dim2)\n",
    "        self.conv3 = GCNConv(hidden_dim2, hidden_dim3)\n",
    "        self.conv4 = GCNConv(hidden_dim3, hidden_dim4)\n",
    "        self.conv5 = GCNConv(hidden_dim4, hidden_dim5)\n",
    "        self.conv6 = GCNConv(hidden_dim5, hidden_dim6)\n",
    "        self.conv7 = GCNConv(hidden_dim6, hidden_dim7)\n",
    "        self.conv8 = GCNConv(hidden_dim7, hidden_dim8)\n",
    "        self.linear = nn.Linear(hidden_dim8, edge_dim)\n",
    "\n",
    "    def forward(self, edge_features, edge_index):\n",
    "        x = self.conv1(edge_features, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv5(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv6(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv7(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv8(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "# Assume edge features are stored in data_training.edge_attr\n",
    "edge_features = data_training.edge_attr\n",
    "\n",
    "# Normalize the edge features\n",
    "max_value = edge_features.max()\n",
    "normalized_edge_features = edge_features / max_value\n",
    "data_training.edge_attr = normalized_edge_features\n",
    "data_testing = data_training.clone()\n",
    "\n",
    "# Get the total number of edges in the dataset\n",
    "total_num_edges = data_training.num_edges\n",
    "\n",
    "# Calculate the number of edges to hide \n",
    "num_edges_to_hide = int(total_num_edges * 0.7)\n",
    "num_remaining_edges = total_num_edges - num_edges_to_hide\n",
    "\n",
    "# Randomly select edges to hide \n",
    "edges_to_hide = random.sample(range(total_num_edges), num_edges_to_hide)\n",
    "remaining_edges = list(set(range(total_num_edges)) - set(edges_to_hide))\n",
    "data_training.edge_attr[edges_to_hide] = -1 #This is questionable\n",
    "\n",
    "# Define the model\n",
    "edge_dim = 1  # Number of edge features\n",
    "hidden_dim1 = 32\n",
    "hidden_dim2 = 128\n",
    "hidden_dim3 = 64\n",
    "hidden_dim4 = 32\n",
    "hidden_dim5 = 32\n",
    "hidden_dim6 = 32\n",
    "hidden_dim7 = 32\n",
    "hidden_dim8 = 32\n",
    "\n",
    "model = GNN(edge_dim, hidden_dim1, hidden_dim2, hidden_dim3, hidden_dim4, hidden_dim5, hidden_dim6, hidden_dim7, hidden_dim8)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "num_epochs = 10000\n",
    "losses = np.zeros(num_epochs)\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(data_training.edge_attr, data_training.edge_index)\n",
    "    \n",
    "    # Compute loss using the predicted features and the input features of the hidden edges\n",
    "    loss = criterion(output[edges_to_hide], data_testing.edge_attr[edges_to_hide])\n",
    "    losses[epoch] = loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
